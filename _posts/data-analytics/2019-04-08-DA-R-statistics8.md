---
layout: post
title:  "[통계학#8] T-test"
date: 2019-04-08 23:55:59
author: Roseline Song
categories: Data-Analytics
tags: R 통계학 강의
cover: "/assets/DataAnalysis.gif"
---

※ K-Mooc 통계학 / 전공 데이터 애널리틱스 강의를 듣고 정리한 내용입니다.

<br>
<br>

### T-test를 쓰는 이유 

**Z-test가 쓰기 어려운 이유**

보통의 상황에서 우리는 모집단의 평균, 시그마(표준편차)를 알 수 없다. Z-test는 표준오차(Standard Error) 계산을 위해 시그마를 알아야 하지만 알지 못하기 때문에 대신 추정치 s를 쓴다. 정규분포에서 표준화를 할 때, 시그마 대신 스탠다드 에러 s를 쓰면 t 분포가 된다.

<br>
<br>

**T-test**

T-test는 μ를 가정 또는 예측한다. 모집단의 변량을 구할 때는 'n'으로 나누지만, **표본의 변량을 구할 때는 'n-1'로 나눈다**. n-1은 자유도(degree of freedom, df)를 뜻한다. n 중에서 제약식 조건 하나를 빼는 이유는 '표본평균'이 주어져야 계산을 할 수 있기 때문이다. 

$$s^2 = \frac{1}{n-1}\sum_{i=1}^N (X_i - \bar{X})^2$$

<br>
<br>

**T-test 특징**

데이터가 적을 수록 꼬리는 두터워진다. 꼬리가 두터워진다는 것은 데이터 중에서 outlier(이상치)가 많다는 것을 의미한다. 따라서, 데이터가 작으면 신뢰 구간은 넓어지고, 데이터가 편향될 가능성이 많아진다. 반대로 샘플 사이즈를 증가시킬 수록 정규 분포의 모양에 수렴된다. 다른 말로 하면, df가 높아질 수록 정규 분포에 수렴한다. 위의 표본변량을 구할 때 n-1로 나누었는데, 샘플 사이즈가 클 수록(분모) 변량(Variance)은 작아지기 때문이다.  


<br>
<br>

<hr>

<br>

### One Sample T-test (단일 표본 T-test)

단일 표본 t 검정은 모집단 하나의 평균(μ)을 기준이 되는 값과 비교하고자 할 때 사용된다. 예를 들어, 서울 소재 대학생들의 평균 토익 점수가 700점이라고 할 때, 어느 서울 소재 대학교의 학생 300명의 평균 토익 점수를 측정해 전국 대학생과 비교할 때 사용할 수 있다. 

$$t = \frac{\bar{X} - μ}{\frac{s}{\sqrt{n}}}$$ 

<br>
<br>

<hr>

<br>

### Two Sample T-test (대표본인 경우)

독립 이표본 T-test는 두 모집단을 비교하는 Two Sample T-test 중에서 각 모집단이 독립일 경우에 시행하는 검정이다. 두 모집단에서 각각 샘플링한다. 예를 들어, 학력에 따른 연봉 차이를 알아보기 위해서 고졸 집단과 대졸 집단 각각에서 표본을 추출해서 비교할 수 있다. 

<br>
<br>


**가정**

1. 두 모집단은 서로 독립이다.
2. 두 모집단의 각 표본의 크기는 충분히 크다.(각각 25이상, 대표본)

<br>
<br>


**계산**

- 목표 : $$E(X) = μ_1 - μ_2$$
- 점추정치 : $$\bar{X} - \bar{Y}$$
- 구간추정 : $$var(\bar{X} + \bar{Y}) = var(\bar{X}) + var(\bar{Y}) = \frac{σ^2}{n_1} + \frac{σ^2}{n_2}$$

변량의 합은 각 변량의 합과 같다. 구간추정에서 $$var(\bar{X} + \bar{Y}) = var(\bar{X}) + var(\bar{Y})$$과 같이 나뉠 수 있는 이유는 **변량의 합은 각 변량의 합과 같기 때문**이다. 

<br>
<br>


**표준화**

$$\frac{\bar{X} - \bar{Y}}{\sqrt{ \frac{s_1^2}{n_1} + \frac{s_2^2}{n_2} }}$$

표본의 크기가 충분히 클 때 중심극한 정리에 따라 표준 정규 분포를 따른다. 시그마는 우리가 알지 못하는 모수이므로 s로 대체한 것이다. 

<br>
<br>


**귀무가설**

$$μ_1 - μ_2 = μ_0$$

두 모집단이 차이가 없다는 것을 밝히고 싶다면 $$μ_0$$을 0으로 세우면 된다. 대립가설을 세울 때는 $$μ_1 ≠ μ_2$$로 세운다. 


<br>
<br>

<hr>

<br>

### 정규분포를 따르는 모집단에 대한 T-test (대표본이 아닌 경우)

이 역시도 Two Sample T-test에 해당하지만, 두 모집단의 표본들이 충분히 크지 않을 경우(두 표본의 크기 모두 25보다 커야 한다.)에 사용한다. 예를 들어 pair test(아래 설명 참고).

<br>
<br>

**표본에 대한 가정**

1. 정규성 : 두 표본은 모두 정규분포를 따른다. <br>
2. 독립성 : 두 모집단은 독립적이다. 단, 통계적으로는 검증할 수 없어서 방법론적인 관점에서 해결해야 한다. <br>
3. 등분산성(Homogeneity) : 모집단 내 변량의 크기는 같다. (두 모집단의 분산이 같은 필요는 없다. 헷갈리지 말아야 한다.) <br>

<br>
<br>

**등분산성 - 집단의 동질성 검증**

개별 집단이 같은 모집단에서 나온 것인지 검증하는 것이다. 같은 모집단에서 나왔다면 개별 집단의 오차변량이 같을 것이고(귀무가설, Null가설), 다른 모집단에서 나왔다면 개별 집단의 오차 변량이 다를 것이다(대립 가설). 같은 집단에게 처음에는 그냥 달리기를 시키고, 그후 술을 마신 후 달리게 한다. 마시기 전과 마시기 후의 두 집단은 '술'이라는 독립변인이 없다면 '변량이 같아야' 한다. 그래야 다른 변인이 섞여있지 않다는 것을 가정할 수 있기 때문이다. 

<br>
<br>

**이분산성 - 등분산성을 만족하지 못하는 경우**

- 독립성을 만족하기 때문에 각 변량으로 나눠서 계산한다. 
- $$n_1 - 1$$과 $$n_2 - 1$$ 중 분수가 더 작아지는 것을 자유도로 설정한다. (분모가 클 수록 분수는 작아지므로, 더 큰 값을 택한다.) 

이분산성인 경우, 두 모집단의 $$σ^2$$이 모두 같다. 소표본의 경우, 정규분포보다 더 정확한 t분포를 사용한다. (따라서, 표본의 크기가 커질 수록 정규분포에 수렴한다는 중심극한정리는 적용되지 않는다.) 

<br>
<br>

**R 코드**

<br>

```R
# 두 모집단 A, B
# length(A) = 13, length(B) = 8
A <- c(79.98, 80.04, 80.02, 80.04, 80.03, 80.03, 80.04, 79.97,
            80.05, 80.03, 80.02, 80.00, 80.02)

B <- c(80.02, 79.94, 79.98, 79.97, 79.97, 80.03, 79.95, 79.97)

# 등분산성을 알려주려면 var.equal=T 옵션 설정
t.test(A, B, var.equal = T) #1 등분산성

# default는 var.equal = F
t.test(A, B) #2 이분산성
```

<br>

 동질성  | t값| 자유도(df) | p-value | 신뢰 구간(95%)
--------|----|-----------|-----------|----------
등분산성 #1| 3.4722 | 19 | 0.002551 | 0.01669058 ~ 0.06734788
이분산성 #2| 3.2499 | 12.027 | 0.006939 | 0.01385526 ~ 0.07018320

<br>


R에서의 결과를 보면 #1에서는 Two sample t-test라고 뜬다. 유의확률은 0.002551로 낮게 나온다. (**유의확률이 작을 수록 귀무가설을 기각할 수 있는 정당성이 커진다.**) 

한편, #2에서는 Welch Two Sample t-test라는 다른 t-test를 사용한다. t값은 비슷하지만, 자유도에서부터 차이가 난다. 이분산성의 경우 $$n_1 - 1$$과 $$n_2 - 1$$ 중에서 분수가 더 작아지는 것을 택하므로, 개수가 더 많은 A (13)의 자유도를 택한 것으로 보인다. **특이한 점은 '소수점' 형태로 자유도**가 나온다는 것이다. 만약, 자유도가 소수점으로 나온다면 이분산성에 근거한 two sample t-test라고 생각하면 된다. 또한, **p-value가 #1보다 훨씬 높다**. **신뢰 구간도 보면 이분산성이 더 넓어서**, 귀무가설을 포함할 확률이 높아진다. 

<br>
<br>

<hr>

<br>

### Pair Test(쌍체 비교)

독립 이표본과 다르게 두 집단이 독립적이지 않은 경우다. 개인 별로 왼쪽, 오른쪽 시력 차이가 있는가? 아스피린 복용 전후의 혈압 차이가 있는가? 등등이 해당된다. 독립인 두 집단이 아니라 한 집단을 대상으로 시간차를 두어 비교한다. 

같은 집단에게 처음에는 그냥 달리기를 시키고, 그후 술을 마신 후 달리게 하자. 같은 집단은 시간 차와 (술을 마시는) 사건을 두고, 두 집단으로 나뉜다. 

<br>
<br>

**R 코드**

```R
# 아스피린 복용 전후 혈압의 변화
x <- c(70, 80, 72, 76, 76, 76, 72, 78, 82, 64, 74, 92, 74, 68, 84)
y <- c(68, 72, 62, 70, 58, 66, 68, 52, 64, 72, 74, 60, 74, 72, 74)

length(x) # 15
length(y) # 15

# method1
t.test(x,y,paired = T, conf.level = 0.95)

# method2 (one-sample로 계산된다.)
d <- x-y
t.test(d)
```


<br>
<br>


**장, 단점**

1. 장점
- 샘플 사이즈가 작아져 경제적이다.
- Variance(변량)이 작아질 수록 가설 검증력이 높아진다. 

Pair test의 경우, 같은 집단을 사용하여 표본 크기가 작어지기 때문에 비용이 훨씬 적게 든다는 장점이 있다. 표본이 적어 모집단을 대표하기 어렵다는 점은 반복 측정(repeated measure)으로 극복한다. 또한, Variance가 작아질 수록 검증력은 높아진다. 

<br>

2. 단점 
- 누적 효과(Carry over effect)
- 순서 효과(Order effect)
- 시험 효과(Test effect)

누적 효과는 측정을 반복하면서 이전의 결과들이 누적되어 다음 시행에 영향을 주는 경우를 말한다. 위의 예시에서 1차 실험에서 1잔, 2차 실험에서 1잔(2잔), 3차 1잔(3잔)... 이렇게 실험을 반복하다 보면 이전의 실험의 결과가 누적되어 같은 1잔이 아니게 된다. 

순서 효과는 시행이 어떤 순서로 일어나느냐에 따라 결과에 영향을 미치는 경우다. 예를 들어, 질문의 순서를 어떻게 하느냐에 따라 다른 답변을 유도할 수 있다. 

testing effect는 피험자가 실험의 의도를 파악해서 다른 변인이 개입되는 것이다. 실험자에게 유리한 쪽 혹은 불리한 쪽으로 행동할 수 있다. 

pair test는 위에서 말한 표본에 대한 가정 3가지를 모두 충족시켜야 한다. 


<br>
<br>

**trimmed mean**

표본이 적다보니 outlier의 영향이 클 수 밖에 없다. 따라서, 극단치 5%를 양 극단에서 쳐내서 왜도를 줄이는데, 이를 trimmed mean이라고 한다. 

<br>
<br>